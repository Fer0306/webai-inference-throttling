# WebAI Inference Throttling Demo

Este proyecto demuestra cÃ³mo implementar **throttling de inferencias** en un modelo de IA ejecutado en el navegador usando **TensorFlow.js**.  
El objetivo es optimizar el uso de recursos en tiempo real, especialmente en dispositivos mÃ³viles, evitando bloqueos o sobrecarga cuando se realizan inferencias continuas desde la cÃ¡mara.

---

## âœ¨ CaracterÃ­sticas principales

- ğŸ“¸ **GestiÃ³n avanzada de la cÃ¡mara**  
  - Cambio de cÃ¡mara (frontal/trasera).  
  - Soporte de diferentes resoluciones: QVGA, VGA, HD, FullHD, 4K.  
  - Control de zoom y linterna (si el dispositivo lo permite).  

- ğŸ§  **Inferencia optimizada con throttling**  
  - Basado en `coco-ssd` de TensorFlow.js.  
  - ConfiguraciÃ³n dinÃ¡mica de frecuencia de inferencia (1â€“10 FPS).  
  - Filtrado de clases de objetos (ejemplo: `cup`, `bottle`).  

- ğŸ¨ **Procesamiento de predicciones**  
  - Dibuja bounding boxes en canvas.  
  - Redibuja solo si las predicciones cambian â†’ ahorro de recursos.  

- ğŸ“± **Interfaz adaptable (responsive)**  
  - Controles intuitivos para cÃ¡mara, linterna, zoom y FPS.  
  - Compatible con desktop, tablet y mÃ³vil.  

---

## ğŸ—ï¸ Arquitectura del proyecto

Este proyecto sigue una arquitectura modular basada en capas inteligentes para optimizar el rendimiento:

1. **Capa de cÃ¡mara (VideoController)**
   Flujo directo desde `getUserMedia()`, con soporte de cambio de cÃ¡mara, encendido/apagado, zoom y linterna.
   Mejoras: cambio de resoluciÃ³n, pause y play.

2. **Capa de modelo (ModelController)**  
   Administra la carga y ejecuciÃ³n del modelo `coco-ssd` de TensorFlow.js.  
   - Permite configurar el *throttling* dinÃ¡mico a las inferencias.  
   - Soporta filtrado de clases.

3. **Capa de procesamiento de predicciones (PredictionProcessor)**
   Procesa las predicciones recibidas y decide cuÃ¡ndo actualizar comparando predicciones (bounding boxes, clases, scores).
   la visualizaciÃ³n en el canvas.   

4. **Capa de renderizado en canvas (pendiente de integrar)**
   En la arquitectura final, esta capa se encargarÃ¡ de manejar de forma independiente el dibujado en el canvas.  

---

## ğŸ”” Nota importante

En este demo, las capas 3 y 4 (**PredictionProcessor** y **Canvas**) todavÃ­a estÃ¡n unificadas dentro de una sola clase.  
Esto se debe a que el cÃ³digo se encuentra en una **versiÃ³n inicial funcional**, pero la separaciÃ³n completa estÃ¡ en la hoja de ruta del proyecto.  

ğŸ‘‰ PrÃ³ximamente, se dividirÃ¡ la lÃ³gica en dos capas independientes:  
- **PredictionProcessor** â†’ solo procesarÃ¡ y filtrarÃ¡ predicciones.  
- **CanvasRenderer** â†’ se encargarÃ¡ exclusivamente de renderizar en el canvas.  

De esta manera, la arquitectura quedarÃ¡ totalmente modular y alineada con lo descrito en el artÃ­culo de Medium.

---

## ğŸ§ª Objetos detectados en la demo

Esta demo estÃ¡ configurada para detectar **Ãºnicamente los siguientes objetos**:

- ğŸ¥¤ `cup`
- ğŸ¼ `bottle`

Esto se debe a que se aplica un **filtro de clases** para reducir la carga de procesamiento y enfocarse en un caso de uso especÃ­fico.  
Puedes modificar o ampliar este filtro desde el archivo JavaScript (`ModelController.js`).

---

## ğŸš€ CÃ³mo probarlo

1. Clona este repositorio o descarga el archivo `index.html`.  
2. Abre `index.html` en tu navegador (se recomienda **Chrome** o **Edge**).  
3. Acepta permisos de cÃ¡mara cuando el navegador los solicite.  
4. Ajusta la frecuencia de inferencia (FPS), cambia de cÃ¡mara o activa la linterna desde la UI.  

Este proyecto demuestra cÃ³mo implementar **throttling de inferencias** en un modelo de IA ejecutado en el navegador usando **TensorFlow.js**.  
El objetivo es optimizar el uso de recursos en tiempo real, especialmente en dispositivos mÃ³viles, evitando bloqueos o sobrecarga cuando se realizan inferencias continuas desde la cÃ¡mara.

ğŸ® **[Â¡Probar la demo en vivo! â†’](https://fer0306.github.io/fernandofa0306/proyectos/1-webai-inference-throttling/index.html)**

---

## ğŸ“‚ Estructura del proyecto

webai-inference-throttling/
â”œâ”€â”€ index.html # Demo principal
â”œâ”€â”€ README.md # DocumentaciÃ³n
â””â”€â”€ LICENSE # Licencia (opcional)



---

## ğŸ“¸ Capturas de pantalla (opcional)

![LimitaciÃ³n de inferencia en WebAI](img/inference-throttling-limit.jpg)

---

## ğŸ“ Licencia

Este proyecto se distribuye bajo la licencia **MIT**.  
Puedes usarlo, modificarlo y compartirlo libremente, siempre dando el crÃ©dito correspondiente.  

---

## ğŸ‘¨â€ğŸ’» Autor

**Fernando Flores Alvarado**  
- ğŸ“§ fernandofa0306@gmail.com  
- ğŸ’¼ [LinkedIn Profile](https://www.linkedin.com/in/fernando-flores-alvarado-2786b21b8/)  
- ğŸ”— [Medium Articles](https://medium.com/@fernandofa0306)
*â€œCompartir con responsabilidad es inspirar para construir el futuro.â€* ğŸš€


---


